{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mgina/.cache\\torch\\hub\\pytorch_vision_v0.8.2\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.8.2', 'alexnet', pretrained=True)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data: if Windows\n",
    "path='../Image/All_Cropped'\n",
    "\n",
    "images={}\n",
    "\n",
    "directory=['Mountain', 'Beach', \n",
    "           'Mug', 'Banana', \n",
    "           'Car', 'Plane', \n",
    "           'Lighthouse', 'Church']\n",
    "\n",
    "for dir in directory:\n",
    "    images[dir]=[file for file in os.listdir(path+'/'+dir) if file.endswith(('jpeg', 'jpg'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute mean and std of all images (cached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess = transforms.Compose([\n",
    "# #     transforms.Resize(256),\n",
    "# #     transforms.CenterCrop(224),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "# all_images = []\n",
    "# for cate, filename in images.items():\n",
    "#     for f in filename:\n",
    "#         dir=os.path.join(path,cate,f)\n",
    "#         img=preprocess(Image.open(dir))\n",
    "# #         if img.shape[1] != 256 or img.shape[2] != 256:\n",
    "# #             print(img.shape)\n",
    "# #             plt.imshow(Image.open(dir))\n",
    "# #             plt.show()\n",
    "#         all_images.append(img)\n",
    "# all_images = torch.stack(all_images).numpy()\n",
    "# print(all_images.shape)\n",
    "# mean = np.mean(all_images, axis=(0,2,3))\n",
    "# std = np.std(all_images, axis=(0,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=mean, std=std),\n",
    "# ])\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # this should be the mean and std for alexnet training dataset\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read labels \n",
    "with open(\"../imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "\n",
    "# read labels to wordnet synsets\n",
    "ltw = pd.read_json('../imagenet_label_to_wordnet_synset.json').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'label', 'uri'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type prob cate+filename\n",
    "all_img={'type':[], 'dir':[],'id_labels':[],'readable_labels':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for cate, filename in images.items():\n",
    "    for f in filename:\n",
    "        dir=os.path.join(path,cate,f)\n",
    "        img=Image.open(dir)\n",
    "        #print(dir)\n",
    "        input_tensor=preprocess(img)\n",
    "        input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            input_batch= input_batch.to('cuda')\n",
    "            model.to('cuda')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(input_batch)\n",
    "        \n",
    "        probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "        top10_prob, top10_catid = torch.topk(probabilities, 10)\n",
    "#         typ_score=round(float(probabilities.max()*100),1)\n",
    "        \n",
    "        # Show top categories per image\n",
    "        top10_prob, top10_catid = torch.topk(probabilities, 10)\n",
    "        temp1 = {}\n",
    "        temp2 = {}\n",
    "        for i in range(top10_prob.size(0)):\n",
    "            temp1[categories[top10_catid[i].item()]] = top10_prob[i].item()\n",
    "            temp2[ltw['id'][top10_catid[i].item()]] = top10_prob[i].item()\n",
    "\n",
    "        all_img['dir'].append(dir)\n",
    "#         all_img['typicality_score'].append(typ_score)\n",
    "        all_img['readable_labels'].append(temp1)\n",
    "        all_img['id_labels'].append(temp2)\n",
    "        if 'Mountain' in cate:\n",
    "            all_img['type'].append('Mountain')\n",
    "        if 'Beach' in cate:\n",
    "            all_img['type'].append('Beach')\n",
    "        if 'Mug' in cate:\n",
    "            all_img['type'].append('Mug')\n",
    "        if 'Banana' in cate:\n",
    "            all_img['type'].append('Banana')\n",
    "        if 'Car' in cate:\n",
    "            all_img['type'].append('Car')\n",
    "        if 'Plane' in cate:\n",
    "            all_img['type'].append('Plane')\n",
    "        if 'Lighthouse' in cate:\n",
    "            all_img['type'].append('Lighthouse')\n",
    "        if 'Church' in cate:\n",
    "            all_img['type'].append('Church')\n",
    "\n",
    "#         print('Typicality of ',f, ' = ',probabilities.max()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>dir</th>\n",
       "      <th>id_labels</th>\n",
       "      <th>readable_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>../Image/All_Cropped\\Mountain\\1.jpg</td>\n",
       "      <td>{'09193705-n': 0.18738645315170288, '09468604-...</td>\n",
       "      <td>{'alp': 0.18738645315170288, 'valley': 0.06126...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>../Image/All_Cropped\\Mountain\\10.jpg</td>\n",
       "      <td>{'09468604-n': 0.6145076155662537, '09193705-n...</td>\n",
       "      <td>{'valley': 0.6145076155662537, 'alp': 0.135453...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>../Image/All_Cropped\\Mountain\\11.jpg</td>\n",
       "      <td>{'09472597-n': 0.7545696496963501, '09193705-n...</td>\n",
       "      <td>{'volcano': 0.7545696496963501, 'alp': 0.18182...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>../Image/All_Cropped\\Mountain\\12.jpg</td>\n",
       "      <td>{'09193705-n': 0.5299694538116455, '09468604-n...</td>\n",
       "      <td>{'alp': 0.5299694538116455, 'valley': 0.397528...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>../Image/All_Cropped\\Mountain\\13.jpg</td>\n",
       "      <td>{'09246464-n': 0.6374799013137817, '09399592-n...</td>\n",
       "      <td>{'cliff': 0.6374799013137817, 'promontory': 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type                                   dir  \\\n",
       "0  Mountain   ../Image/All_Cropped\\Mountain\\1.jpg   \n",
       "1  Mountain  ../Image/All_Cropped\\Mountain\\10.jpg   \n",
       "2  Mountain  ../Image/All_Cropped\\Mountain\\11.jpg   \n",
       "3  Mountain  ../Image/All_Cropped\\Mountain\\12.jpg   \n",
       "4  Mountain  ../Image/All_Cropped\\Mountain\\13.jpg   \n",
       "\n",
       "                                           id_labels  \\\n",
       "0  {'09193705-n': 0.18738645315170288, '09468604-...   \n",
       "1  {'09468604-n': 0.6145076155662537, '09193705-n...   \n",
       "2  {'09472597-n': 0.7545696496963501, '09193705-n...   \n",
       "3  {'09193705-n': 0.5299694538116455, '09468604-n...   \n",
       "4  {'09246464-n': 0.6374799013137817, '09399592-n...   \n",
       "\n",
       "                                     readable_labels  \n",
       "0  {'alp': 0.18738645315170288, 'valley': 0.06126...  \n",
       "1  {'valley': 0.6145076155662537, 'alp': 0.135453...  \n",
       "2  {'volcano': 0.7545696496963501, 'alp': 0.18182...  \n",
       "3  {'alp': 0.5299694538116455, 'valley': 0.397528...  \n",
       "4  {'cliff': 0.6374799013137817, 'promontory': 0....  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_img_df=pd.DataFrame(all_img)\n",
    "all_img_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_img_df['label'] = all_img_df['top5_labels'].apply(lambda x: list(x.keys())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_img_df['7_score']=round(all_img_df['typicality_score']*7/100,1)\n",
    "# all_img_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score=[]\n",
    "# for i in range(5):\n",
    "#     dir=all_img_df['dir'][i]\n",
    "#     score.append([all_img_df['typicality_score'][i], all_img_df['7_score'][i]])\n",
    "#     img=Image.open(dir)\n",
    "#     plt.imshow(img)\n",
    "#     plt.title(score[i])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_img_df.to_csv('alexnet_scores_wordnet_id.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
